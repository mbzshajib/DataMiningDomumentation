\documentclass[a4paper,12pt]{book}
\usepackage[english]{babel}	
\usepackage[nottoc]{tocbibind}
\usepackage{graphicx}  
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{fixltx2e}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{array}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{todonotes}
\usepackage[]{algorithm2e}

\begin{document}
\chapter{Our Proposed Approaches}
\input{pa_intro}
\section{Uncertain Stream Data Properties}
In this chapter we will talk about data properties. our data has two special properties. (1)Stream and (2)Uncertainty. For these properties it becomes very much hard to get valuable and interesting information from data. So first we discuss about the data set properties.
\input{../example/table_uncertain_transaction}
\input{pa_properties}
\newpage
\section{Preliminaries}
\input{pa_preliminaries}
\input{../example/table_uncertain_transaction_batch}
\section{Mining Frequent Patterns from Uncertain Databases}
Our proposed algorithm is divided into five parts. (1) Grouping transactions into batches and window and giving each item in a transaction a prefix value is called \emph{U\textsuperscript{cap}}. (2) insert transaction into \emph {US-tree}. (3) sliding the \emph {US-tree} (4) mining the \emph {US-tree} with \emph{USFP-growth} algorithm and (5) Eliminating false positive (not frequent but exists in frequent item set) . For simulating our approach we consider Table~\ref{table:uncertain_stream_transaction} as uncertain stream transaction data. For this simulation we consider window size as 2 and batch size 3. That means 3 transactions creates a batch and 2 batches create a window. After completing window construction (inserting batch 1 and 2) the \emph {US-tree} will be full. When new batch comes we slide the window. That means we remove oldest batch batch-1 and put batch-2 as the old batch. Then insert new batch in the tree as batch-3. So for window size 2 the tree always contains at most 2 batches. Thus the tree always holds the latest information. In next subsections we will elaborately explain our approach of every steps.
\subsection{Preparation}
\input{../example/table_prefix}
\input{pa_preparation}
\subsection{US-tree Construction}
\input{pa_tree}
\subsection{Mining US-tree FPUS-growth}
\input{pa_mining}
\newpage
\subsection{False positive reduction}
\input{pa_elimination}
\newpage
\subsection{Algorithm}
\input{pa_algorithm}

%\section{Summary}
%\input{pa_summary}
\end{document}